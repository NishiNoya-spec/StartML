{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Логистическая регрессия \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def log_reg_clf_hitrate(x_random_state, x_features_train, x_target_train, x_features_test, x_target_test, c_w):\n",
    "    print(\"LogisticRegression\")\n",
    "    LR_max_hitrate = 0\n",
    "    LR_hitrate_C = 0\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=x_random_state)\n",
    "    LR_data_metrix = []\n",
    "\n",
    "    for i in range(-3, 4, 1):\n",
    "        x_c = 10**i  # Свободный член регрессии\n",
    "\n",
    "        fold_metrics = []\n",
    "\n",
    "        for fold, (train_idx, valid_idx) in enumerate(kf.split(x_features_train, x_target_train)):\n",
    "            x_features_fold_train, x_features_valid = x_features_train.iloc[train_idx], x_features_train.iloc[valid_idx]\n",
    "            x_target_fold_train, x_target_valid = x_target_train.iloc[train_idx], x_target_train.iloc[valid_idx]\n",
    "\n",
    "            model = LogisticRegression(random_state=x_random_state, solver='liblinear', class_weight=c_w, C=x_c)\n",
    "            model.fit(x_features_fold_train, x_target_fold_train)\n",
    "\n",
    "            # Оценка метрики hitrate@5 на валидационных данных\n",
    "            hitrate = calculate_hitrate_at_5(model, x_features_valid, x_target_valid)\n",
    "            fold_metrics.append(hitrate)\n",
    "\n",
    "        avg_hitrate = np.mean(fold_metrics)\n",
    "        LR_data_metrix.append([avg_hitrate, x_c])\n",
    "\n",
    "        if LR_max_hitrate < avg_hitrate:\n",
    "            LR_max_hitrate = avg_hitrate\n",
    "            LR_hitrate_C = x_c\n",
    "\n",
    "    LR_data_metrix = pd.DataFrame(LR_data_metrix, columns=['hitrate', 'x_c'])\n",
    "    display(LR_data_metrix)\n",
    "    LR_data_metrix[\"best_C\"] = LR_hitrate_C\n",
    "    LR_data_metrix[\"max_train_hitrate\"] = LR_max_hitrate\n",
    "    print('Максимум Hitrate =', LR_max_hitrate, '| свободный член регрессии С=', LR_hitrate_C)\n",
    "\n",
    "    # Обучение на всем трейне с лучшими гиперпараметрами\n",
    "    best_model = LogisticRegression(random_state=x_random_state, solver='liblinear', class_weight=c_w, C=LR_hitrate_C)\n",
    "    best_model.fit(x_features_train, x_target_train)\n",
    "\n",
    "    # Оценка на тестовых данных\n",
    "    hitrate_test = calculate_hitrate_at_5(best_model, x_features_test, x_target_test)\n",
    "    print(f'Test Hitrate@5: {hitrate_test:.4f}')\n",
    "\n",
    "    LR_data_metrix[\"max_test_hitrate\"] = hitrate_test\n",
    "    \n",
    "    # Отбор важных фичей на основе коэффициентов модели с учетом знака\n",
    "    importances = best_model.coef_[0]\n",
    "    feature_importance = pd.DataFrame(\n",
    "        importances,\n",
    "        index=x_features_train.columns,\n",
    "        columns=['importance']\n",
    "    ).sort_values(by='importance', ascending=False)\n",
    "\n",
    "    # Построение графика важности признаков\n",
    "    plot_feature_importances(feature_importance=feature_importance, model_name=f\"Logistic Regression {c_w}\", target_type=\"Hitrate@5\")\n",
    "\n",
    "    return best_model, LR_data_metrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пропишем классификаторы для исследования моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Функция для построения гистограммы важности признаков\n",
    "def plot_feature_importances(feature_importance, model_name, target_type):\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=True)\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    plt.barh(feature_importance.index, feature_importance.importance, height=0.7)\n",
    "    plt.xlabel('Importance', fontsize=12)\n",
    "    plt.ylabel('Features', fontsize=12)\n",
    "    plt.title(f'{model_name} - {target_type} - Feature Importance', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "### Строит матрицу путаниц для оценки качества классификации\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def ax_plot_confusion_matrix(ax, y_true, y_pred, labels=None, title=\"Confusion Matrix\"): \n",
    "    # Вычисляем матрицу путаниц \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels) \n",
    "    # Создаем объект для отображения матрицы путаниц \n",
    "    cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels) \n",
    "    # Отображаем матрицу путаниц на графике \n",
    "    cmp.plot(ax=ax) \n",
    " \n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "def print_clf(df_LR, df_DT, df_RF, df_LGBM):\n",
    "    \"\"\"\n",
    "    Функция вывода максимальных значений Hitrate@5 и гиперпараметров.\n",
    "    На вход принимает таблицы значений Hitrate@5 по параметрам.\n",
    "    \"\"\"\n",
    "    result_metrix = []\n",
    "\n",
    "    models = {\n",
    "        \"LogisticRegression\": df_LR,\n",
    "        \"DecisionTreeClassifier\": df_DT,\n",
    "        \"RandomForestClassifier\": df_RF,\n",
    "        \"LGBMClassifier\": df_LGBM\n",
    "    }\n",
    "\n",
    "    for model_name, df in models.items():\n",
    "        print(model_name)\n",
    "        \n",
    "        max_hitrate_idx = df['hitrate'].idxmax()\n",
    "        max_hitrate_row = df.loc[max_hitrate_idx]\n",
    "        \n",
    "        print('Максимум Hitrate@5 =', max_hitrate_row['hitrate'])\n",
    "        print('Тренировочные данные: Hitrate@5 =', max_hitrate_row['max_train_hitrate'])\n",
    "        print('Тестовые данные: Hitrate@5 =', max_hitrate_row['max_test_hitrate'])\n",
    "        print('Гиперпараметры:')\n",
    "        for param in df.columns:\n",
    "            if param not in ['hitrate', 'max_train_hitrate', 'max_test_hitrate', 'best_C', 'best_depth', 'best_n_estimators']:\n",
    "                print(f'  {param}: {max_hitrate_row[param]}')\n",
    "        \n",
    "        result_metrix.append([\n",
    "            model_name, \n",
    "            max_hitrate_row['hitrate'], \n",
    "            max_hitrate_row['max_train_hitrate'], \n",
    "            max_hitrate_row['max_test_hitrate'],\n",
    "            {param: max_hitrate_row[param] for param in df.columns if param not in ['hitrate', 'max_train_hitrate', 'max_test_hitrate', 'best_C', 'best_depth', 'best_n_estimators']}\n",
    "        ])\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    final_metrix = pd.DataFrame(result_metrix, columns=['Classifier', 'Hitrate@5', 'Train Hitrate@5', 'Test Hitrate@5', 'Best Params'])\n",
    "    return final_metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Напишем классификаторы\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "### 1. Логистическая регрессия \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def log_reg_clf_hitrate(x_random_state, x_features_train, x_target_train, x_features_test, x_target_test, c_w):\n",
    "    print(\"LogisticRegression\")\n",
    "    LR_max_hitrate = 0\n",
    "    LR_hitrate_C = 0\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=x_random_state)\n",
    "    LR_data_metrix = []\n",
    "\n",
    "    for i in range(-3, 4, 1):\n",
    "        x_c = 10**i  # Свободный член регрессии\n",
    "\n",
    "        fold_metrics = []\n",
    "\n",
    "        for fold, (train_idx, valid_idx) in enumerate(kf.split(x_features_train, x_target_train)):\n",
    "            x_features_fold_train, x_features_valid = x_features_train.iloc[train_idx], x_features_train.iloc[valid_idx]\n",
    "            x_target_fold_train, x_target_valid = x_target_train.iloc[train_idx], x_target_train.iloc[valid_idx]\n",
    "\n",
    "            model = LogisticRegression(random_state=x_random_state, solver='liblinear', class_weight=c_w, C=x_c)\n",
    "            model.fit(x_features_fold_train, x_target_fold_train)\n",
    "\n",
    "            # Оценка метрики hitrate@5 на валидационных данных\n",
    "            hitrate = calculate_hitrate_at_5(model, x_features_valid, x_target_valid)\n",
    "            fold_metrics.append(hitrate)\n",
    "\n",
    "        avg_hitrate = np.mean(fold_metrics)\n",
    "        LR_data_metrix.append([avg_hitrate, x_c])\n",
    "\n",
    "        if LR_max_hitrate < avg_hitrate:\n",
    "            LR_max_hitrate = avg_hitrate\n",
    "            LR_hitrate_C = x_c\n",
    "\n",
    "    LR_data_metrix = pd.DataFrame(LR_data_metrix, columns=['hitrate', 'x_c'])\n",
    "    display(LR_data_metrix)\n",
    "    LR_data_metrix[\"best_C\"] = LR_hitrate_C\n",
    "    LR_data_metrix[\"max_train_hitrate\"] = LR_max_hitrate\n",
    "    print('Максимум Hitrate =', LR_max_hitrate, '| свободный член регрессии С=', LR_hitrate_C)\n",
    "\n",
    "    # Обучение на всем трейне с лучшими гиперпараметрами\n",
    "    best_model = LogisticRegression(random_state=x_random_state, solver='liblinear', class_weight=c_w, C=LR_hitrate_C)\n",
    "    best_model.fit(x_features_train, x_target_train)\n",
    "\n",
    "    # Оценка на тестовых данных\n",
    "    hitrate_test = calculate_hitrate_at_5(best_model, x_features_test, x_target_test)\n",
    "    print(f'Test Hitrate@5: {hitrate_test:.4f}')\n",
    "\n",
    "    LR_data_metrix[\"max_test_hitrate\"] = hitrate_test\n",
    "    \n",
    "    # Отбор важных фичей на основе коэффициентов модели с учетом знака\n",
    "    importances = best_model.coef_[0]\n",
    "    feature_importance = pd.DataFrame(\n",
    "        importances,\n",
    "        index=x_features_train.columns,\n",
    "        columns=['importance']\n",
    "    ).sort_values(by='importance', ascending=False)\n",
    "\n",
    "    # Построение графика важности признаков\n",
    "    plot_feature_importances(feature_importance=feature_importance, model_name=f\"Logistic Regression {c_w}\", target_type=\"Hitrate@5\")\n",
    "\n",
    "    return best_model, LR_data_metrix\n",
    "\n",
    "\n",
    "### 2. Дерево решений\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def dec_tre_clf_hitrate(x_random_state, x_features_train, x_target_train, x_features_test, x_target_test, c_w):\n",
    "    print(\"DecisionTreeClassifier\")\n",
    "    DT_max_hitrate = 0\n",
    "    DT_hitrate_depth = 0\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=x_random_state)\n",
    "    DT_data_metrix = []\n",
    "\n",
    "    for depth in range(4, 51, 2):\n",
    "        fold_metrics = []\n",
    "\n",
    "        for fold, (train_idx, valid_idx) in enumerate(kf.split(x_features_train, x_target_train)):\n",
    "            x_features_fold_train, x_features_valid = x_features_train.iloc[train_idx], x_features_train.iloc[valid_idx]\n",
    "            x_target_fold_train, x_target_valid = x_target_train.iloc[train_idx], x_target_train.iloc[valid_idx]\n",
    "\n",
    "            model = DecisionTreeClassifier(max_depth=depth, random_state=x_random_state, class_weight=c_w)\n",
    "            model.fit(x_features_fold_train, x_target_fold_train)\n",
    "\n",
    "            # Оценка метрики hitrate@5 на валидационных данных\n",
    "            hitrate = calculate_hitrate_at_5(model, x_features_valid, x_target_valid)\n",
    "            fold_metrics.append(hitrate)\n",
    "\n",
    "        avg_hitrate = np.mean(fold_metrics)\n",
    "        DT_data_metrix.append([avg_hitrate, depth])\n",
    "\n",
    "        if DT_max_hitrate < avg_hitrate:\n",
    "            DT_max_hitrate = avg_hitrate\n",
    "            DT_hitrate_depth = depth\n",
    "\n",
    "    DT_data_metrix = pd.DataFrame(DT_data_metrix, columns=['hitrate', 'depth'])\n",
    "    display(DT_data_metrix)\n",
    "    DT_data_metrix[\"best_depth\"] = DT_hitrate_depth\n",
    "    DT_data_metrix[\"max_train_hitrate\"] = DT_max_hitrate\n",
    "    print('Максимум Hitrate =', DT_max_hitrate, '| глубина дерева = ', DT_hitrate_depth)\n",
    "\n",
    "    # Обучение на всем трейне с лучшими гиперпараметрами\n",
    "    best_model = DecisionTreeClassifier(max_depth=DT_hitrate_depth, random_state=x_random_state, class_weight=c_w)\n",
    "    best_model.fit(x_features_train, x_target_train)\n",
    "\n",
    "    # Оценка на тестовых данных\n",
    "    hitrate_test = calculate_hitrate_at_5(best_model, x_features_test, x_target_test)\n",
    "    print(f'Test Hitrate@5: {hitrate_test:.4f}')\n",
    "\n",
    "    DT_data_metrix[\"max_test_hitrate\"] = hitrate_test\n",
    "    \n",
    "    # Отбор важных фичей на основе коэффициентов модели\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance = pd.DataFrame(\n",
    "        importances,\n",
    "        index=x_features_train.columns,\n",
    "        columns=['importance']\n",
    "    ).sort_values(by='importance', ascending=False)\n",
    "\n",
    "    # Построение графика важности признаков\n",
    "    plot_feature_importances(feature_importance=feature_importance, model_name=f\"Decision Tree {c_w}\", target_type=\"Hitrate@5\")\n",
    "\n",
    "    return best_model, DT_data_metrix\n",
    "\n",
    "\n",
    "### 3. Случайный лес\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def ran_for_clf_hitrate(x_random_state, x_features_train, x_target_train, x_features_test, x_target_test, c_w):\n",
    "    print(\"RandomForestClassifier\")\n",
    "    \n",
    "    RF_max_Hitrate = 0\n",
    "    RF_Hitrate_n_estimators = 0\n",
    "    RF_Hitrate_depth = 0\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=x_random_state)\n",
    "    RF_data_metrix = []\n",
    "    \n",
    "    for depth in range(6, 11, 2):\n",
    "        for estim in range(50, 301, 50):\n",
    "            fold_metrics = {\n",
    "                'hitrate': []\n",
    "            }\n",
    "            \n",
    "            for fold, (train_idx, valid_idx) in enumerate(kf.split(x_features_train, x_target_train)):\n",
    "                x_features_fold_train, x_features_valid = x_features_train.iloc[train_idx], x_features_train.iloc[valid_idx]\n",
    "                x_target_fold_train, x_target_valid = x_target_train.iloc[train_idx], x_target_train.iloc[valid_idx]\n",
    "                \n",
    "                model = RandomForestClassifier(n_estimators=estim, max_depth=depth, random_state=x_random_state, class_weight=c_w)\n",
    "                model.fit(x_features_fold_train, x_target_fold_train)\n",
    "                \n",
    "                hitrate = calculate_hitrate_at_5(model, x_features_valid, x_target_valid)\n",
    "                fold_metrics['hitrate'].append(hitrate)\n",
    "            \n",
    "            avg_hitrate = np.mean(fold_metrics['hitrate'])\n",
    "            RF_data_metrix.append([avg_hitrate, depth, estim])\n",
    "\n",
    "            if RF_max_Hitrate < avg_hitrate:\n",
    "                RF_max_Hitrate = avg_hitrate\n",
    "                RF_Hitrate_n_estimators = estim\n",
    "                RF_Hitrate_depth = depth\n",
    "\n",
    "    RF_data_metrix = pd.DataFrame(RF_data_metrix, columns=['hitrate', 'depth', 'estim'])\n",
    "    display(RF_data_metrix)\n",
    "    RF_data_metrix[\"best_depth\"] = RF_Hitrate_depth\n",
    "    RF_data_metrix[\"best_n_estimators\"] = RF_Hitrate_n_estimators\n",
    "    RF_data_metrix[\"max_train_hitrate\"] = RF_max_Hitrate\n",
    "    print('Максимум Hitrate@5 =', RF_max_Hitrate, '| число деревьев = ', RF_Hitrate_n_estimators, '| глубина дерева = ', RF_Hitrate_depth)\n",
    "    \n",
    "    best_model = RandomForestClassifier(n_estimators=RF_Hitrate_n_estimators, max_depth=RF_Hitrate_depth, random_state=x_random_state, class_weight=c_w)\n",
    "    best_model.fit(x_features_train, x_target_train)\n",
    "    \n",
    "    hitrate_test = calculate_hitrate_at_5(best_model, x_features_test, x_target_test)\n",
    "    print('Hitrate@5 на тестовых данных =', hitrate_test)\n",
    "    \n",
    "    RF_data_metrix[\"max_test_hitrate\"] = hitrate_test\n",
    "    \n",
    "    # Отбор важных фичей на основе коэффициентов модели\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance = pd.DataFrame(\n",
    "        importances,\n",
    "        index=x_features_train.columns,\n",
    "        columns=['importance']\n",
    "    ).sort_values(by='importance', ascending=False)\n",
    "\n",
    "    # Построение графика важности признаков\n",
    "    plot_feature_importances(feature_importance=feature_importance, model_name=f\"Random Forest {c_w}\", target_type=\"Hitrate@5\")\n",
    "    \n",
    "    return best_model, RF_data_metrix\n",
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "def lgbm_clf_hitrate(x_random_state, x_features_train, x_target_train, x_features_test, x_target_test, c_w):\n",
    "    print(\"LightGBMClassifier\")\n",
    "    \n",
    "    lgbm_max_Hitrate = 0\n",
    "    lgbm_Hitrate_depth = 0\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=x_random_state)\n",
    "    lgbm_data_metrix = []\n",
    "    \n",
    "    for depth in range(4, 51, 2):\n",
    "        fold_metrics = {\n",
    "            'hitrate': []\n",
    "        }\n",
    "        \n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.8,\n",
    "            'max_cat_threshold': 25,\n",
    "            'min_data_in_leaf': 10,\n",
    "            'num_threads': 4,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'max_depth': depth,\n",
    "            'class_weight': c_w\n",
    "        }\n",
    "        \n",
    "        for fold, (train_idx, valid_idx) in enumerate(kf.split(x_features_train, x_target_train)):\n",
    "            x_features_fold_train, x_features_valid = x_features_train.iloc[train_idx], x_features_train.iloc[valid_idx]\n",
    "            x_target_fold_train, x_target_valid = x_target_train.iloc[train_idx], x_target_train.iloc[valid_idx]\n",
    "            \n",
    "            model = LGBMClassifier(**params)\n",
    "            model.fit(x_features_fold_train, x_target_fold_train)\n",
    "            \n",
    "            hitrate = calculate_hitrate_at_5(model, x_features_valid, x_target_valid)\n",
    "            fold_metrics['hitrate'].append(hitrate)\n",
    "        \n",
    "        avg_hitrate = np.mean(fold_metrics['hitrate'])\n",
    "        lgbm_data_metrix.append([avg_hitrate, depth])\n",
    "    \n",
    "        if lgbm_max_Hitrate < avg_hitrate:\n",
    "            lgbm_max_Hitrate = avg_hitrate\n",
    "            lgbm_Hitrate_depth = depth\n",
    "\n",
    "    lgbm_data_metrix = pd.DataFrame(lgbm_data_metrix, columns=['hitrate', 'depth'])\n",
    "    display(lgbm_data_metrix)\n",
    "    lgbm_data_metrix[\"best_depth\"] = lgbm_Hitrate_depth\n",
    "    lgbm_data_metrix[\"max_train_hitrate\"] = lgbm_max_Hitrate  \n",
    "    print('Максимум Hitrate@5 =', lgbm_max_Hitrate, '| глубина дерева = ', lgbm_Hitrate_depth)\n",
    "    \n",
    "    best_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'max_cat_threshold': 25,\n",
    "        'min_data_in_leaf': 10,\n",
    "        'num_threads': 4,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'max_depth': lgbm_Hitrate_depth,\n",
    "        'class_weight': c_w\n",
    "    }\n",
    "    \n",
    "    best_model = LGBMClassifier(**best_params)\n",
    "    best_model.fit(x_features_train, x_target_train)\n",
    "    \n",
    "    hitrate_test = calculate_hitrate_at_5(best_model, x_features_test, x_target_test)\n",
    "    print('Hitrate@5 на тестовых данных =', hitrate_test)\n",
    "    \n",
    "    lgbm_data_metrix[\"max_test_hitrate\"] = hitrate_test  \n",
    "    \n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance = pd.DataFrame(\n",
    "        importances,\n",
    "        index=x_features_train.columns,\n",
    "        columns=['importance']\n",
    "    ).sort_values(by='importance', ascending=False)\n",
    "\n",
    "    # Построение графика важности признаков\n",
    "    plot_feature_importances(feature_importance=feature_importance, model_name=f\"LGBM {c_w}\", target_type=\"Hitrate@5\")\n",
    "    \n",
    "    return best_model, lgbm_data_metrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
